# Projekt-Kontext: Tree Species Classification

**Zweck:** Dieses Dokument fasst grundlegendes strukturelles Wissen Ã¼ber das Projekt zusammen, um bei zukÃ¼nftigen Entwicklungsarbeiten schnell den Kontext wiederherzustellen.

---

## ProjektÃ¼bersicht

**Thema:** Machine Learning fÃ¼r Baumgattungs-Klassifikation in deutschen StÃ¤dten basierend auf Sentinel-2 Satellitendaten

**Kernfrage:** Wie gut transferieren ML-Modelle zwischen verschiedenen StÃ¤dten (Berlin, Hamburg, Rostock)?

**Wissenschaftlicher Fokus:**

- Cross-City Transfer Learning fÃ¼r urbane Baumkartierung
- Vergleich verschiedener ML-Paradigmen (Tree-based vs. Neural Networks)
- Praktische Anwendbarkeit mit begrenzten lokalen Daten (Fine-Tuning)

**Projektrahmen:**

- Einzelperson, 1 Semester
- Ressourcen-Constraints fÃ¼hren zu pragmatischen Entscheidungen
- Fokus auf reproduzierbare, nachvollziehbare Methodik

---

## Projektstruktur & Organisation

### Ordnerstruktur

```
project/
â”œâ”€â”€ data/                          # Alle Daten (NICHT in Git)
â”‚   â”œâ”€â”€ 01_raw/                   # Rohdaten aus Downloads
â”‚   â”œâ”€â”€ 02_pipeline/              # Pipeline-Zwischenergebnisse
â”‚   â””â”€â”€ 03_experiments/           # Experiment-spezifische Daten
â”œâ”€â”€ scripts/                       # Python-Skripte fÃ¼r Datenverarbeitung
â”‚   â”œâ”€â”€ config.py                 # Zentrale Konfiguration
â”‚   â”œâ”€â”€ boundaries/               # Stadt-Grenzen Download
â”‚   â”œâ”€â”€ tree_cadastres/           # Baumkataster Verarbeitung
â”‚   â”œâ”€â”€ chm/                      # Canopy Height Model
â”‚   â””â”€â”€ elevation/                # GelÃ¤ndehÃ¶hen
â”œâ”€â”€ notebooks/                     # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_processing/            # Datenverarbeitung
â”‚   â”œâ”€â”€ 02_feature_engineering/   # Feature-Extraktion
â”‚   â””â”€â”€ 03_experiments/           # ML-Experimente
â”‚       â”œâ”€â”€ 00_phase_0/           # Setup-Ablationsstudien
â”‚       â””â”€â”€ 01_phase_1/           # Algorithmus-Vergleich
â”œâ”€â”€ docs/                          # Dokumentation
â”‚   â”œâ”€â”€ arbeitsprotokolle/        # WÃ¶chentliche Arbeitsprotokolle
â”‚   â”œâ”€â”€ documentation/            # Methodikdokumentation
â”‚   â””â”€â”€ gpt_knowledge/            # Kompakte Zusammenfassungen
â”œâ”€â”€ results/                       # Experiment-Ergebnisse
â””â”€â”€ pyproject.toml                # Python-Projekt-Konfiguration
```

### Wichtige Konventionen

**Dateinamen:**

- Notebooks: `NN_description.ipynb` (mit fÃ¼hrender Nummer fÃ¼r Reihenfolge)
- Scripts: `snake_case.py`
- Daten: `city_config_split.format` (z.B. `berlin_20m_edge_train.gpkg`)
- Metadaten: `descriptive_name.json/csv`

**Notebook-Struktur (Standard-Template):**

1. Overview & Methodology
2. Setup & Imports
3. Configuration & Parameters
4. [Verarbeitungsschritte - je nach Notebook]
5. Validation & Summary
6. Summary & Next Steps

**Python-Konventionen:**

- Python 3.13.5
- Dependencies in `pyproject.toml` (uv als Package Manager)
- Google Colab als primÃ¤re AusfÃ¼hrungsumgebung (GPU-Zugriff)
- Lokale Entwicklung in VSCode mit Jupyter

---

## Datenstruktur & Formate

### Geografische Daten

**PrimÃ¤rformat:** GeoPackage (`.gpkg`)

- Wird fÃ¼r alle rÃ¤umlichen Zwischenschritte verwendet
- EnthÃ¤lt Geometrie + alle Features
- CRS: EPSG:25832 (UTM Zone 32N fÃ¼r Deutschland)

**ML-Format:** Parquet (`.parquet`)

- FÃ¼r finale Feature-Datasets ohne Geometrie
- Deutlich schneller zu laden als GeoPackage
- Genutzt in Phase 1+ Experimenten

### Feature-Struktur

**Temporale Features:**

- 8 Monate Sentinel-2 Daten (April-November, Vegetationsperiode)
- Monatliche Aggregation (Median) zur Rauschreduktion
- Feature-Format: `{basename}_{month}` (z.B. `B04_apr`, `ndvi_jul`)

**Feature-Gruppen:**

- Spektrale BÃ¤nder: B02-B12 (10m/20m resample auf 10m)
- Vegetation Indices: NDVI, EVI, VARI, SAVI, etc.
- Red-Edge Indices: NDREI, IRECI, CIred-edge, etc.
- Water Indices: NDWI, NDII
- Optional: CHM (Canopy Height Model) - mit Vorsicht wegen Overfitting

**Feature-Engineering Pipeline:**

- Feature-Extraktion: Zeitreihen-Statistiken (Median, Std, Slopes, etc.)
- NaN-Handling: Spatial Imputation (median of 8-nearest neighbors)
- Outlier Detection: IQR-basiert mit outlier_flag (nicht automatisch gefiltert)
- Plausibility Checks: Domain-spezifische Schwellwerte

### Daten-Splits

**Spatial Block Split (500m):**

- Verhindert rÃ¤umliches Leakage zwischen Train/Val/Test
- Berlin/Hamburg: 70/20/10 (Train/Val/Test)
- Rostock: 50/50 (Zero-Shot/Fine-Tune-Eval)
- Stratifiziert nach Genus (Klassenbalance)

**Wichtig:** Normalisierung (StandardScaler) immer nur auf Train fitten, dann auf Val/Test anwenden!

---

## Experiment-Philosophie & Methodik

### Phasen-Struktur

Das Projekt folgt einer strikten Phasen-Struktur:

**Phase 0: Setup-Ablation** (Fixiere Basis-Konfiguration)

- Exp 0.1: CHM-Strategie â†’ Entscheidung: No CHM (Overfitting-Risiko)
- Exp 0.2: Dataset-Wahl â†’ Entscheidung: 20m-Edge (6 Genera, spektral rein)
- Exp 0.3: Feature Reduction â†’ Entscheidung: Top-50 (102.5% Retention vs. All)

**Phase 1: Algorithmus-Vergleich** (Single-City Ranking)

- Coarse HP-Tuning auf Berlin
- Ziel: 1 ML (RF/XGBoost) + 1 NN (TabNet/CNN) fÃ¼r Phase 2
- Limitation: Single-City Selection fÃ¼r Transfer-Ziel (pragmatisch wegen Ressourcen)

**Phase 2: Transfer Evaluation**

- Berlinâ†’Rostock, Hamburgâ†’Rostock, Combinedâ†’Rostock
- Vergleich ML vs. NN Transfer-Robustheit

**Phase 3: Fine-Tuning**

- Wie viel lokale Daten kompensieren Transfer-Verlust?

**Phase 4: Post-hoc Analysen**

- Exp 4.1: Tree-Type-Effekt
- Exp 4.2: Genus-spezifische Transfer-Analyse
- Exp 4.3: Feature-Gruppen-Contribution
- Exp 4.4: Real-World-Robustheit
- Exp 4.5: Outlier-Removal Ablation

### Entscheidungsprinzipien

**Occam's Razor:**

- Bei Ã¤hnlicher Performance (Î” < 2-3%): Einfacheres Modell/weniger Features wÃ¤hlen
- BegrÃ¼ndung: Bessere Generalisierung, weniger Overfitting-Risiko

**Wissenschaftliche Ehrlichkeit:**

- Limitationen offen benennen (z.B. "Single-City Selection fÃ¼r Transfer-Ziel")
- Overfitting-Probleme nicht verschweigen
- Unsicherheiten dokumentieren

**Pragmatismus:**

- Ressourcen-Constraints akzeptieren und dokumentieren
- "Good enough" statt "perfekt" wenn Zeit/Rechenleistung begrenzt
- Coarse Grid Search statt exhaustive fÃ¼r schnelles Ranking

**Reproduzierbarkeit:**

- Random Seed: 42 (Ã¼berall)
- Alle Entscheidungen in Markdown dokumentiert
- Config-Files fÃ¼r alle Experimente

---

## Dokumentations-Stil

### Methodikdokumentation (docs/documentation/)

**Prinzip:** "PrÃ¤gnant, nur was gemacht wurde, nicht vorgreifen"

**Struktur pro Experiment:**

1. **Forschungsfrage** - Was wird getestet?
2. **Methodik** - Wie wurde getestet? (kompakt, Tabellen bevorzugt)
3. **Ergebnisse** - Was kam raus? (Zahlen, Plots)
4. **Entscheidung & BegrÃ¼ndung** - Was wurde gewÃ¤hlt und warum?
5. **Designentscheidungen** - Trade-offs und Rationale
6. **Validierung** - Sanity Checks und PlausibilitÃ¤t

**Stil-Referenz:** Phase 0 Dokumentation

- ~460 Zeilen fÃ¼r 3 Experimente
- Keine Vorgriffe auf zukÃ¼nftige Experimente
- Ehrlich Ã¼ber Limitationen
- [PLATZHALTER] fÃ¼r noch nicht ausgefÃ¼hrte Teile

**Anti-Pattern:**

- âŒ Lange Einleitungen
- âŒ ErklÃ¤rung von Basis-ML-Konzepten
- âŒ Detaillierte Hyperparameter-Beschreibungen (nur in Tabellen)
- âŒ Redundante Wiederholungen

### Arbeitsprotokolle (docs/arbeitsprotokolle/)

**Format:** WÃ¶chentlich, Markdown

- Datum im Dateinamen: `AP_XX_YYYY-MM-DD_bis_YYYY-MM-DD.md`
- Struktur: Ziele â†’ DurchgefÃ¼hrt â†’ Probleme â†’ NÃ¤chste Schritte
- Bilder im Unterordner `bilder/`

### GPT-Knowledge (docs/gpt_knowledge/)

**Zweck:** Kompakte Zusammenfassungen fÃ¼r schnelles Einlesen

- Aggregiert aus detaillierter Dokumentation
- Max 1-2 Seiten pro Phase
- Fokus auf Entscheidungen und Ergebnisse

---

## Technische Details

### Python-Environment

**Package Manager:** uv (modern, schnell)

```bash
uv sync  # Dependencies installieren
uv add package_name  # Package hinzufÃ¼gen
```

**Wichtige Dependencies:**

- geopandas, rasterio: Geodaten
- scikit-learn: ML-Basics
- xgboost: Gradient Boosting
- pytorch-tabnet: TabNet (pip install nicht via uv wegen KomplexitÃ¤t)
- matplotlib, seaborn: Visualisierung

### Google Colab Integration

**Mount-Point:** `/content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit`

**Workflow:**

1. Notebook lokal in VSCode entwickeln
2. In Colab hochladen fÃ¼r AusfÃ¼hrung (GPU)
3. Outputs zurÃ¼ck in Drive synced

**Pro-Tipp:** BASE_DIR in Config-Cell fÃ¼r lokale/Colab AusfÃ¼hrung

### Git & Version Control

**Wichtig:** `data/` Ordner ist in `.gitignore`!

- Nur Code und Dokumentation in Git
- Daten zu groÃŸ fÃ¼r GitHub
- Backup Ã¼ber Google Drive

**Branch-Strategie:**

- `main`: Stabile Version
- Feature-Branches bei Bedarf

---

## HÃ¤ufige Stolpersteine & LÃ¶sungen

### Problem: Spatial Leakage

**LÃ¶sung:** Spatial Block CV (500m Blocks), nie Standard Random Split bei rÃ¤umlichen Daten

### Problem: CHM-Overfitting

**Symptom:** 100% Train Accuracy, 47% Train-Val Gap
**LÃ¶sung:** CHM weglassen oder heavy regularization (Phase 0 Entscheidung)

### Problem: Memory bei groÃŸen GeoPackages

**LÃ¶sung:**

- Parquet fÃ¼r ML-Workflows
- Subsample fÃ¼r schnelles Prototyping
- Colab Runtime mit High-RAM

### Problem: NaN in Features

**LÃ¶sung:**

- Spatial Imputation (8-nearest neighbors) statt globaler Median
- Validierung nach jedem Verarbeitungsschritt

### Problem: Class Imbalance

**LÃ¶sung:**

- `class_weight='balanced'` in RF/XGBoost
- Custom class_weights in PyTorch
- Stratified Sampling in Splits

### Problem: Inkonsistente Feature-Namen

**LÃ¶sung:**

- Zentrale `selected_features.json` aus Phase 0
- Validierung in jedem Notebook (validate_features() Funktion)

---

## Best Practices (aus dem Projekt gelernt)

### Notebooks

1. **Utility-Funktionen** immer am Anfang definieren (print_section, validate_features, etc.)
2. **Sektion-Header** mit `print_section()` fÃ¼r Ãœbersichtlichkeit in Colab-Output
3. **Validation** nach jedem grÃ¶ÃŸeren Schritt (NaN-Check, Feature-Count, Genus-Balance)
4. **Export Summary** am Ende mit Statistiken

### Datenverarbeitung

1. **Pipeline-Struktur:** `01_raw â†’ 02_pipeline â†’ 03_experiments`
2. **Intermediate Outputs:** GeoPackage mit allen Features fÃ¼r FlexibilitÃ¤t
3. **Metadata Files:** JSON fÃ¼r Metadaten (data_prep_report.json), CSV fÃ¼r tabellarische Auswertungen
4. **Plots speichern:** Immer als PNG mit 300 DPI

### Experimente

1. **Config-First:** Alle Parameter in Config-Cells, keine Magic Numbers im Code
2. **Output-Struktur:** Jedes Experiment eigener Ordner mit standardisierten Dateien
3. **Reproducibility:** Random Seed, sklearn-Versionen, Colab-Runtime-Type dokumentieren
4. **Ablation-Prinzip:** Eine Variable pro Experiment Ã¤ndern

### Dokumentation

1. **Concurrent:** WÃ¤hrend Experiment, nicht nachtrÃ¤glich
2. **Decision-First:** Entscheidung + BegrÃ¼ndung wichtiger als alle Details
3. **Visual:** Tabellen und Plots bevorzugen statt lange Texte
4. **Honest:** Limitations nicht verschweigen

---

## Projekt-Status & Deliverables

### Abgeschlossen (Stand: 20. Januar 2026)

- âœ… Phase 0: Alle 3 Experimente (CHM, Dataset, Features)
- âœ… Phase 0 Dokumentation (prÃ¤gnanter Stil etabliert)
- âœ… Phase 1: Data Preparation (6 Parquet-Datasets)
- âœ… Phase 1 Dokumentation (Template mit Platzhaltern)

### In Progress

- ðŸ”µ Phase 1: Algorithm Comparison (Notebook erstellt, noch nicht ausgefÃ¼hrt)
  - 01_algorithm_comparison Notebook (RF, XGBoost, TabNet)
  - Expected Runtime: 3-4h in Colab

### Geplant

- âšª Phase 2: Transfer Evaluation
- âšª Phase 3: Fine-Tuning
- âšª Phase 4: Post-hoc Analysen (inkl. Outlier-Removal Ablation)

### Finale Deliverables (Semesterende)

- Dokumentation aller Experimente (Markdown)
- Trained Models (Best ML + Best NN)
- Transfer-Evaluation Report
- Arbeitsprotokolle (wÃ¶chentlich)
- Optional: Paper-Draft

---

## Kommunikation & PrÃ¤ferenzen

**Sprache:**

- Dokumentation: Deutsch (fÃ¼r deutschsprachige Publikation)
- Code/Variablen: Englisch (Standard in ML)
- Kommentare: Deutsch bevorzugt

**Dateiformate:**

- Dokumentation: Markdown (nicht Word/PDF bis finaler Export)
- Code: Jupyter Notebooks fÃ¼r Exploration, Scripts fÃ¼r Produktion
- Plots: PNG (300 DPI)
- Daten: GeoPackage (Processing), Parquet (ML)

**Arbeitsweise:**

- Iterativ: Erst prototypen, dann dokumentieren
- Bottom-up: Aus Notebooks extrahieren, nicht top-down planen
- Pragmatisch: "Good enough" mit dokumentierten Limitationen

---

## NÃ¼tzliche Referenzen im Projekt

**Haupt-Dokumente:**

- `docs/documentation/03_Experiments/00_Experiment_Design.md` - GesamtÃ¼bersicht aller Experimente
- `docs/documentation/03_Experiments/01_Phase_0_Methodik.md` - Stil-Referenz fÃ¼r Dokumentation
- `scripts/config.py` - Zentrale Pfade und Konstanten
- `notebooks/TEMPLATE_NOTEBOOK.ipynb` - Notebook-Template

**Config-Files:**

- `data/03_experiments/00_phase_0/03_experiment_feature_reduction/metadata/selected_features.json` - Finale Feature-Liste (Top-50)
- `data/03_experiments/01_phase_1/00_data_preparation/metadata/data_prep_report.json` - Dataset-Statistiken

---

**Letzte Aktualisierung:** 20. Januar 2026  
**Projekt-Phase:** Phase 1 (Algorithm Comparison in Progress)
