# Improvements & Roadmap

**Datum:** 6. Januar 2026  
**Zweck:** Sammlung von methodischen Varianten, Ablationsstudien und Optimierungen, die noch nicht implementiert wurden aber potenzielle Verbesserungen darstellen.

---

## üìã Status-Legende

- üîÑ **In Progress** - Aktuell in Bearbeitung
- üìã **Planned** - Geplant f√ºr zuk√ºnftige Phasen
- üí° **Proposed** - Idee/Vorschlag, noch nicht genehmigt
- ‚ùå **Rejected** - Verworfen nach Evaluation
- ‚úÖ **Completed** - Implementiert und dokumentiert

---

## 1. Phase 1: Data Processing Improvements

### 1.1 Alternative Interpolationsmethoden f√ºr CHM

**Status:** üí° Proposed

**Aktuell:** Mean/Max/Std Aggregation (1m ‚Üí 10m) via windowed resampling

**Alternative Ans√§tze:**

- **Spline Interpolation:** Smooth transitions zwischen Pixeln
- **LOESS (Locally Estimated Scatterplot Smoothing):** Adaptive lokale Regression
- **Kriging:** Geostatistische Interpolation mit Spatial Autocorrelation

**Potenzielle Vorteile:**

- Glattere H√∂henmodelle
- Weniger Artefakte an Blockgrenzen
- Bessere Repr√§sentation von Kronenformen

**Potenzielle Nachteile:**

- Erh√∂hte Rechenzeit
- Oversmoothing ‚Üí Verlust von Kronendetails
- Schwieriger zu interpretieren

**N√§chste Schritte:**

- Literaturrecherche: CHM-Interpolation Best Practices
- Prototyp mit scipy.interpolate.RBFInterpolator
- Vergleichsstudie: Mean vs Spline (visuell + quantitativ)

---

## 2. Phase 2: Feature Engineering Improvements

### 2.1 Sentinel-2 Zeitfenster: 7 Monate vs 12 Monate

**Status:** üí° Proposed

**Aktuell:** 12 Monate (Jan-Dez 2021) mit monatlichen Medianen

**Alternative:** 7 Monate (Apr-Okt) - Vegetationsperiode only

**Begr√ºndung f√ºr 7-Monats-Variante:**

- **Ph√§nologische Vollst√§ndigkeit:** Austrieb ‚Üí Vollbelaubung ‚Üí Herbstf√§rbung
- **Cloud Coverage:** Deutlich h√∂her in Vegetationsperiode (70-100% Verf√ºgbarkeit vs. 30-50% Winter)
- **Literatur:** +1-2% OA f√ºr zweites Jahr, aber nicht proportional zum Aufwand
- **Feature Reduktion:** 10 B√§nder √ó 7 Monate = 70 Features (statt 120)

**Trade-offs:**
| Aspekt | 12 Monate (aktuell) | 7 Monate (alternativ) |
|---|---|---|
| **Ph√§nologie** | Vollst√§ndig inkl. Winter-Ruhe | Nur Vegetationsperiode |
| **Cloud Coverage** | Problematisch (Winter 30-50%) | Sehr gut (70-100%) |
| **Feature-Anzahl** | 120 spektrale Features | 70 spektrale Features |
| **Dimensionalit√§t** | H√∂her ‚Üí ggf. Overfitting | Niedriger ‚Üí bessere Generalisierung? |
| **Evergreens vs Deciduous** | Winterdifferenzierung m√∂glich | Nur Sommer-Signaturen |

**Ablationsstudie (geplant f√ºr Exp 4):**

- Train Modell A: 12 Monate (aktuell)
- Train Modell B: 7 Monate (Apr-Okt)
- Vergleich: OA, F1 pro Genus, Confusion Matrix
- Hypothese: Deciduous profitieren von 7-Monats (weniger Noise), Evergreens ggf. schlechter

**Implementierung:**

- Feature Extraction Notebook anpassen: `MONTHS = [4,5,6,7,8,9,10]`
- Feature Matrix neu exportieren
- Normalization/Training pipeline unver√§ndert

---

### 2.2 IQR-basierte Outlier Detection (Alternative zu spektralem Threshold)

**Status:** üí° Proposed

**Aktuell:** NDVI < 0.3 + spektrale Hard-Thresholds (B04 > 8000, B08 > 8000)

**Alternative:** IQR-Methode (Interquartile Range)

**Methodischer Ansatz:**

```python
# Pro Feature:
Q1 = feature.quantile(0.25)
Q3 = feature.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Remove trees outside [lower_bound, upper_bound]
```

**Begr√ºndung:**

- **Adaptiv:** Automatische Schwellenwerte pro Feature
- **Robust:** Funktioniert f√ºr alle spektralen B√§nder/Indizes
- **Literatur-Standard:** Weit verbreitete statistische Methode

**Potenzielle Vorteile:**

- Erkennt mehr Artefakte (z.B. Cloud-Masking-Fehler, Sensor-Rauschen)
- Kein manuelles Tuning von Schwellenwerten n√∂tig

**Potenzielle Nachteile:**

- Verlust von ~5-10% Daten (je nach Contamination)
- Schwieriger zu interpretieren (was ist "Ausrei√üer" bei Baumart?)

**N√§chste Schritte:**

- Prototyp in Feature Validation Notebook
- Vergleich: Spektral-Threshold vs IQR (Datenverlust, OA, F1)
- Visuell: Welche B√§ume werden entfernt? (QGIS Plots)

---

### 2.3 Multivariate Outlier Detection: Isolation Forest

**Status:** üí° Proposed

**Aktuell:** Univariate Outlier Detection (pro Feature einzeln)

**Alternative:** Isolation Forest (sklearn.ensemble.IsolationForest)

**Methodischer Ansatz:**

```python
from sklearn.ensemble import IsolationForest

iso_forest = IsolationForest(
    contamination=0.05,  # 5% als Outlier
    random_state=42
)

# Fit auf alle Features gleichzeitig
outliers = iso_forest.fit_predict(X_features)  # -1 = outlier

# Remove outliers
trees_cleaned = trees[outliers == 1]
```

**Begr√ºndung:**

- **Multivariate:** Erkennt ungew√∂hnliche **Feature-Kombinationen**
- **Geisterb√§ume:** Label-Fehler im Kataster (z.B. "QUERCUS" aber spektral wie TILIA)
- **Literatur:** Standard f√ºr anomaly detection in high-dimensional data

**Potenzielle Vorteile:**

- Findet B√§ume mit physikalisch unm√∂glichen Feature-Kombinationen
- Reduziert Label-Noise

**Potenzielle Nachteile:**

- Verlust von weiteren ~5% Daten
- Rechenintensiv bei 240k+ B√§umen
- Hyperparameter-Tuning (contamination) subjektiv

**N√§chste Schritte:**

- Prototyp mit 10% Datensample
- Analyse: Welche B√§ume werden als Outlier markiert? (Feature-Plots)
- Ablation: Modell mit/ohne Isolation Forest Filtering

---

## 3. Phase 3: Model Training Improvements (Planned)

### 3.1 Hyperparameter Optimization: Bayesian vs Grid Search

**Status:** üìã Planned

**Aktuell:** Geplant GridSearchCV f√ºr Random Forest

**Alternative:** Bayesian Optimization (z.B. Optuna, scikit-optimize)

**Begr√ºndung:**

- **Effizienter:** Intelligente Suche statt brute-force
- **Literatur:** 10-50√ó schneller als Grid Search bei gleicher Performance

**N√§chste Schritte:**

- Vergleichsstudie: GridSearch vs Bayesian (Runtime, Best Params, OA)

---

### 3.2 Deep Learning: Transformer-based Models (Optional)

**Status:** üí° Proposed

**Aktuell:** CNN (Convolutional Neural Network) geplant

**Alternative:** Vision Transformer (ViT) oder Swin Transformer

**Begr√ºndung:**

- **State-of-the-Art:** Transformers √ºbertreffen CNNs in vielen Remote Sensing Tasks
- **Attention Mechanism:** Lernt wichtige spektrale B√§nder/Zeitpunkte automatisch

**Trade-offs:**

- **Data Hungry:** Ben√∂tigt deutlich mehr Trainingsdaten
- **Rechenintensiv:** GPU-Training n√∂tig
- **Komplexit√§t:** Schwieriger zu interpretieren

**N√§chste Schritte:**

- Literaturrecherche: Transformer f√ºr Vegetation Classification
- Prototyp nur wenn Random Forest/CNN-Baselines etabliert

---

## 4. Phase 4: Ablation Studies (Exp 4)

### 4.1 Edge-Filter Ablation: Trade-off Quantifizierung

**Status:** üìã Planned

**Aktuell:** 4 Varianten implementiert (no_edge, 15m, 20m, 30m), aber nur edge_15m trainiert

**Ablationsstudie:**

| Variant      | Datenmenge             | Spektrale Reinheit   | Erwartete OA | Trade-off               |
| ------------ | ---------------------- | -------------------- | ------------ | ----------------------- |
| **no_edge**  | 1,140,172 B√§ume (100%) | Niedrig (Mischpixel) | Baseline     | Urbane Realit√§t         |
| **edge_15m** | 363,571 B√§ume (32%)    | Mittel-Hoch          | +2-5% ?      | Remote Sensing Standard |
| **edge_20m** | 280,522 B√§ume (25%)    | Hoch                 | +3-7% ?      | Balance                 |
| **edge_30m** | 195,117 B√§ume (17%)    | Sehr Hoch            | +5-10% ?     | Upper Bound             |

**Forschungsfragen:**

1. Wie viel OA gewinnen wir pro Filter-Stufe?
2. Gibt es Genera-spezifische Effekte? (z.B. TILIA profitiert mehr als BETULA?)
3. Ab welchem Filter-Level flacht Kurve ab? (Diminishing Returns)

**Implementierung:**

- Train 4 separate Random Forest Modelle (identische Hyperparameter)
- Evaluate auf identischem Testset (z.B. Rostock Zero-Shot)
- Plot: Edge-Distance vs OA/F1

**Literatur-Kontext:**

- Remote Sensing Best Practice: 2√ó Pixelgr√∂√üe (= 20m f√ºr 10m Pixel)
- Hyperspektral-Analogie: 3√ó Pixelgr√∂√üe f√ºr vollst√§ndige Isolation

---

### 4.2 CHM-only vs S2-only vs Combined (Feature Importance)

**Status:** üìã Planned

**Ablation:**

- **Modell A (CHM-only):** Nur height_mean, height_max, height_std (3 Features)
- **Modell B (S2-only):** Nur Sentinel-2 Spektral + Indizes (180 Features)
- **Modell C (Combined):** Alle Features (184 Features)

**Erwartete Resultate:**

- CHM-only: ~60-70% OA (Literatur: H√∂he allein ist starker Pr√§diktor)
- S2-only: ~80-85% OA (Spektral enth√§lt meiste Information)
- Combined: ~87-92% OA (Synergieeffekt)

**N√§chste Schritte:**

- Train alle 3 Varianten
- Feature Importance Analysis (SHAP values)
- Confusion Matrix Vergleich: Welche Genera profitieren von CHM?

---

## 5. Data Quality Improvements

### 5.1 Temporale Diskrepanz: CHM 2021 vs plant_year Filter

**Status:** ‚ùå Rejected / Nicht mehr relevant

**Kontext (historisch):**

- Alte Planung: CHM 2021, aber S2 2024 ‚Üí Zeitliche Diskrepanz
- Problem: B√§ume wachsen ~0,3-0,5m/Jahr ‚Üí Systematische H√∂henuntersch√§tzung

**Aktueller Stand:**

- **Gel√∂st:** Projekt nutzt Sentinel-2 2021 (identisch mit CHM)
- Filter `plant_year ‚â§ 2021` ist jetzt irrelevant

**Dokumentation:** Keine Aktion n√∂tig, bereits korrekt implementiert.

---

## 6. Cross-City Transfer Enhancements

### 6.1 Domain Adaptation: Adversarial Learning (Advanced)

**Status:** üí° Proposed (Forschungsrichtung)

**Kontext:**

- Aktuell: Naive Transfer (Hamburg+Berlin ‚Üí Rostock)
- Problem: Distribution Shift zwischen St√§dten

**Alternative:** Domain Adversarial Neural Network (DANN)

**Methodischer Ansatz:**

- Trainiere Klassifikator + Domain Discriminator gleichzeitig
- Klassifikator lernt genus-features
- Discriminator versucht Stadt zu erraten
- Adversarial Loss: Klassifikator t√§uscht Discriminator

**Begr√ºndung:**

- **Literatur:** State-of-the-Art f√ºr Domain Transfer in Remote Sensing
- **Ziel:** City-invariante Features lernen

**Trade-offs:**

- Sehr komplex
- Ben√∂tigt Deep Learning Infrastructure
- Nur sinnvoll wenn naive Transfer nicht funktioniert

**N√§chste Schritte:**

- Erst Exp 2 (naive Transfer) durchf√ºhren
- Wenn OA < 70%: Domain Adaptation evaluieren
- Literatur: Ganin et al. (2016) "Domain-Adversarial Training"

---

## 7. Operationelle Deployment

### 7.1 Fine-Tuning Strategie: Minimum Data Requirements

**Status:** üìã Planned (Exp 3)

**Forschungsfrage:**

> Wie viele gelabelte B√§ume ben√∂tigt eine neue Stadt (z.B. Wismar) mindestens f√ºr akzeptable Performance?

**Ablationsstudie (geplant):**

- Baseline: Hamburg+Berlin ‚Üí Rostock (Zero-Shot)
- Exp 3.1: + 50 Rostock Samples (Fine-Tuning)
- Exp 3.2: + 100 Rostock Samples
- Exp 3.3: + 500 Rostock Samples

**Metrik:**

- OA vs. Anzahl Fine-Tuning Samples
- Kosten-Nutzen-Analyse: Labeling-Aufwand vs. Accuracy-Gewinn

**N√§chste Schritte:**

- Rostock Subset sampling (stratified by genus)
- Iteratives Fine-Tuning mit wachsenden Samples

---

## 8. Visualization & Interpretability

### 8.1 SHAP Values f√ºr Feature Importance

**Status:** üìã Planned

**Ziel:** Erkl√§rbarkeit der Random Forest Predictions

**Implementierung:**

```python
import shap

explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)

# Plot: Feature Importance pro Genus
shap.summary_plot(shap_values, X_test, class_names=genus_labels)
```

**Output:**

- Welche Features sind wichtig f√ºr TILIA vs QUERCUS?
- Ph√§nologische Muster: Welche Monate sind entscheidend?

---

## 9. Literatur & Methodische Referenzen

**Spatial Autocorrelation:**

- Roberts et al. (2017). "Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure". _Ecography_.

**Remote Sensing Best Practices:**

- Fassnacht et al. (2016). "Review of studies on tree species classification from remotely sensed data". _Remote Sensing of Environment_.

**Domain Adaptation:**

- Ganin et al. (2016). "Domain-Adversarial Training of Neural Networks". _JMLR_.

**Outlier Detection:**

- Liu et al. (2008). "Isolation Forest". _IEEE ICDM_.

---

## 10. Priorit√§ten & Roadmap

### Kurzfristig (Phase 3 - Model Training)

1. ‚úÖ Edge-Filter Ablation (Exp 4.1) - **HIGH Priority**
2. ‚úÖ CHM-only vs S2-only (Exp 4.2) - **HIGH Priority**
3. üìã Hyperparameter Optimization (Grid Search) - **MEDIUM Priority**

### Mittelfristig (Nach Baseline)

1. üí° Sentinel-2 Zeitfenster (7 vs 12 Monate) - **MEDIUM Priority**
2. üí° IQR/Isolation Forest Outlier Detection - **LOW Priority**
3. üí° Bayesian Optimization - **LOW Priority**

### Langfristig (Advanced Research)

1. üí° Transformer-based Models - **Optional**
2. üí° Domain Adaptation (DANN) - **Only if necessary**

---

## 11. Change Log

| Datum      | Autor          | √Ñnderung                                                     |
| ---------- | -------------- | ------------------------------------------------------------ |
| 2026-01-06 | Silas Pignotti | Initial creation, methodische Entscheidungen aus alten Chats |
