{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920c413c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. OVERVIEW & METHODOLOGY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d4c742",
   "metadata": {},
   "source": [
    "### 1.1 Purpose\n",
    "\n",
    "Dieses Notebook führt das Resampling von hochauflösenden Canopy Height Model (CHM) Daten durch:\n",
    "- **Input:** CHM-Raster mit 1m räumlicher Auflösung\n",
    "- **Output:** CHM-Raster mit 10m räumlicher Auflösung in drei Aggregationen:\n",
    "  - **Mean:** Durchschnittliche Baumhöhe pro 10m-Pixel\n",
    "  - **Max:** Maximale Baumhöhe pro 10m-Pixel\n",
    "  - **Std:** Standardabweichung der Baumhöhen pro 10m-Pixel\n",
    "\n",
    "**Methodische Optimierungen:**\n",
    "- Windowed/kachelbasierte Verarbeitung zur RAM-Reduktion\n",
    "- Sequentielle Aggregation (mean → max → std)\n",
    "- Memory-mapped Arrays für effiziente I/O\n",
    "- Geschätzter RAM-Bedarf: ~1-2GB statt 6-8GB\n",
    "\n",
    "**Hardware-Anforderung:** Google Colab Standard (12GB RAM) ausreichend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5ff90",
   "metadata": {},
   "source": [
    "### 1.2 Workflow\n",
    "\n",
    "```\n",
    "[PHASE 1: DATA LOADING]\n",
    "├── Step 1.1: Mount Google Drive\n",
    "├── Step 1.2: Load CHM_1m rasters for all cities\n",
    "└── Step 1.3: Validate input data integrity\n",
    "\n",
    "    ↓\n",
    "\n",
    "[PHASE 2: WINDOWED RESAMPLING]\n",
    "├── Step 2.1: Generate tile windows (512×512 pixels)\n",
    "├── Step 2.2: Process tiles sequentially:\n",
    "│   ├── Mean aggregation (10×10 pixel blocks → 1 pixel)\n",
    "│   ├── Max aggregation\n",
    "│   └── Std aggregation (requires ≥2 valid values)\n",
    "└── Step 2.3: Write output rasters with updated metadata\n",
    "\n",
    "    ↓\n",
    "\n",
    "[PHASE 3: VALIDATION & EXPORT]\n",
    "├── Step 3.1: Generate processing statistics\n",
    "├── Step 3.2: Create validation visualizations\n",
    "└── Step 3.3: Export resampled CHM files\n",
    "\n",
    "    ↓\n",
    "\n",
    "[OUTPUT: CHM_10m rasters for Berlin, Hamburg, Rostock]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedbb763",
   "metadata": {},
   "source": [
    "### 1.3 Expected Outputs\n",
    "\n",
    "| File                     | Type       | Description                                      |\n",
    "| ------------------------ | ---------- | ------------------------------------------------ |\n",
    "| CHM_10m_mean_Berlin.tif  | GeoTIFF    | Mean aggregated CHM (10m resolution)             |\n",
    "| CHM_10m_max_Berlin.tif   | GeoTIFF    | Max aggregated CHM (10m resolution)              |\n",
    "| CHM_10m_std_Berlin.tif   | GeoTIFF    | Std aggregated CHM (10m resolution)              |\n",
    "| CHM_10m_mean_Hamburg.tif | GeoTIFF    | Mean aggregated CHM (10m resolution)             |\n",
    "| CHM_10m_max_Hamburg.tif  | GeoTIFF    | Max aggregated CHM (10m resolution)              |\n",
    "| CHM_10m_std_Hamburg.tif  | GeoTIFF    | Std aggregated CHM (10m resolution)              |\n",
    "| CHM_10m_mean_Rostock.tif | GeoTIFF    | Mean aggregated CHM (10m resolution)             |\n",
    "| CHM_10m_max_Rostock.tif  | GeoTIFF    | Max aggregated CHM (10m resolution)              |\n",
    "| CHM_10m_std_Rostock.tif  | GeoTIFF    | Std aggregated CHM (10m resolution)              |\n",
    "| processing_stats.json    | JSON       | Processing statistics (timing, memory, coverage) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06357de7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. SETUP & IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6052c",
   "metadata": {},
   "source": [
    "### 2.1 Packages & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for geospatial processing\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1005a61",
   "metadata": {},
   "source": [
    "### 2.2 Visualization & Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PUBLICATION_STYLE = {\n",
    "    'style': 'seaborn-v0_8-whitegrid',\n",
    "    'figsize': (12, 7),\n",
    "    'dpi_export': 300,\n",
    "}\n",
    "\n",
    "def setup_publication_style():\n",
    "    plt.rcdefaults()\n",
    "    plt.style.use(PUBLICATION_STYLE['style'])\n",
    "    sns.set_palette('Set2')\n",
    "    plt.rcParams['figure.figsize'] = PUBLICATION_STYLE['figsize']\n",
    "    plt.rcParams['savefig.dpi'] = PUBLICATION_STYLE['dpi_export']\n",
    "    print(\"✓ Publication Style konfiguriert\")\n",
    "\n",
    "setup_publication_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_windows(width, height, tile_size, scale_factor):\n",
    "    \"\"\"\n",
    "    Generiert nicht-überlappende Kachel-Fenster für ein Raster.\n",
    "    \n",
    "    Args:\n",
    "        width: Rasterbreite in Pixeln\n",
    "        height: Rasterhöhe in Pixeln\n",
    "        tile_size: Kachelgröße in Pixeln (Eingabe-Auflösung)\n",
    "        scale_factor: Skalierungsfaktor (z.B. 10 für 1m→10m)\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple[Window, Window]]: (input_window, output_window) Paare\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    \n",
    "    for row_off in range(0, height, tile_size):\n",
    "        for col_off in range(0, width, tile_size):\n",
    "            # Input-Fenster (1m Auflösung)\n",
    "            win_height = min(tile_size, height - row_off)\n",
    "            win_width = min(tile_size, width - col_off)\n",
    "            input_window = Window(col_off, row_off, win_width, win_height)\n",
    "            \n",
    "            # Output-Fenster (10m Auflösung)\n",
    "            out_col = col_off // scale_factor\n",
    "            out_row = row_off // scale_factor\n",
    "            out_width = (win_width + scale_factor - 1) // scale_factor\n",
    "            out_height = (win_height + scale_factor - 1) // scale_factor\n",
    "            output_window = Window(out_col, out_row, out_width, out_height)\n",
    "            \n",
    "            windows.append((input_window, output_window))\n",
    "    \n",
    "    return windows\n",
    "\n",
    "\n",
    "def resample_tile_mean_max(data, scale_factor, nodata=-9999):\n",
    "    \"\"\"\n",
    "    Resample eine Kachel zu mean und max.\n",
    "    \n",
    "    Args:\n",
    "        data: Input-Array (H, W)\n",
    "        scale_factor: Skalierungsfaktor (10 für 1m→10m)\n",
    "        nodata: NoData-Wert\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: (mean_array, max_array)\n",
    "    \"\"\"\n",
    "    h, w = data.shape\n",
    "    new_h = (h + scale_factor - 1) // scale_factor\n",
    "    new_w = (w + scale_factor - 1) // scale_factor\n",
    "    \n",
    "    # Maske für gültige Werte\n",
    "    valid_mask = data != nodata\n",
    "    \n",
    "    # Output-Arrays initialisieren\n",
    "    mean_out = np.full((new_h, new_w), nodata, dtype=np.float32)\n",
    "    max_out = np.full((new_h, new_w), nodata, dtype=np.float32)\n",
    "    \n",
    "    # Aggregation über Blöcke\n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            row_start = i * scale_factor\n",
    "            row_end = min(row_start + scale_factor, h)\n",
    "            col_start = j * scale_factor\n",
    "            col_end = min(col_start + scale_factor, w)\n",
    "            \n",
    "            block = data[row_start:row_end, col_start:col_end]\n",
    "            mask = valid_mask[row_start:row_end, col_start:col_end]\n",
    "            \n",
    "            if mask.any():\n",
    "                valid_values = block[mask]\n",
    "                mean_out[i, j] = valid_values.mean()\n",
    "                max_out[i, j] = valid_values.max()\n",
    "    \n",
    "    return mean_out, max_out\n",
    "\n",
    "\n",
    "def resample_tile_std(data, scale_factor, nodata=-9999):\n",
    "    \"\"\"\n",
    "    Resample eine Kachel zu std.\n",
    "    \n",
    "    Args:\n",
    "        data: Input-Array (H, W)\n",
    "        scale_factor: Skalierungsfaktor (10 für 1m→10m)\n",
    "        nodata: NoData-Wert\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: std_array\n",
    "    \"\"\"\n",
    "    h, w = data.shape\n",
    "    new_h = (h + scale_factor - 1) // scale_factor\n",
    "    new_w = (w + scale_factor - 1) // scale_factor\n",
    "    \n",
    "    valid_mask = data != nodata\n",
    "    std_out = np.full((new_h, new_w), nodata, dtype=np.float32)\n",
    "    \n",
    "    for i in range(new_h):\n",
    "        for j in range(new_w):\n",
    "            row_start = i * scale_factor\n",
    "            row_end = min(row_start + scale_factor, h)\n",
    "            col_start = j * scale_factor\n",
    "            col_end = min(col_start + scale_factor, w)\n",
    "            \n",
    "            block = data[row_start:row_end, col_start:col_end]\n",
    "            mask = valid_mask[row_start:row_end, col_start:col_end]\n",
    "            \n",
    "            if mask.sum() >= 2:  # Mindestens 2 Werte für std\n",
    "                valid_values = block[mask]\n",
    "                std_out[i, j] = valid_values.std()\n",
    "    \n",
    "    return std_out\n",
    "\n",
    "\n",
    "def resample_chm_windowed(input_path, output_paths, tile_size, scale_factor):\n",
    "    \"\"\"\n",
    "    Resample CHM von 1m auf 10m mit kachelbasierter Verarbeitung.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Pfad zu CHM_1m.tif\n",
    "        output_paths: Dict mit keys 'mean', 'max', 'std'\n",
    "        tile_size: Kachelgröße in Pixeln (Eingabe-Auflösung)\n",
    "        scale_factor: Skalierungsfaktor (z.B. 10)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\nVerarbeite: {input_path.name}\")\n",
    "    \n",
    "    stats = {\n",
    "        'input_file': input_path.name,\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'tile_count': 0,\n",
    "        'output_files': {}\n",
    "    }\n",
    "    \n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Output-Dimensionen berechnen\n",
    "        out_height = (src.height + scale_factor - 1) // scale_factor\n",
    "        out_width = (src.width + scale_factor - 1) // scale_factor\n",
    "        \n",
    "        # Output-Transform berechnen\n",
    "        out_transform = src.transform * src.transform.scale(\n",
    "            src.width / out_width,\n",
    "            src.height / out_height\n",
    "        )\n",
    "        \n",
    "        # Metadaten für Output\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            'height': out_height,\n",
    "            'width': out_width,\n",
    "            'transform': out_transform,\n",
    "            'dtype': 'float32',\n",
    "            'compress': 'lzw'\n",
    "        })\n",
    "        \n",
    "        # Output-Dateien vorbereiten\n",
    "        datasets = {\n",
    "            'mean': rasterio.open(output_paths['mean'], 'w', **out_meta),\n",
    "            'max': rasterio.open(output_paths['max'], 'w', **out_meta),\n",
    "            'std': rasterio.open(output_paths['std'], 'w', **out_meta)\n",
    "        }\n",
    "        \n",
    "        # Kachel-Fenster generieren\n",
    "        windows = get_tile_windows(src.width, src.height, tile_size, scale_factor)\n",
    "        stats['tile_count'] = len(windows)\n",
    "        print(f\"Anzahl Kacheln: {len(windows)}\")\n",
    "        print(f\"Output-Dimensionen: {out_height} × {out_width} Pixel\")\n",
    "        \n",
    "        # Phase 1: Mean + Max\n",
    "        print(\"\\nPhase 1/2: Mean + Max Aggregation\")\n",
    "        for input_win, output_win in tqdm(windows, desc=\"Mean+Max\"):\n",
    "            data = src.read(1, window=input_win)\n",
    "            mean_tile, max_tile = resample_tile_mean_max(data, scale_factor)\n",
    "            datasets['mean'].write(mean_tile, 1, window=output_win)\n",
    "            datasets['max'].write(max_tile, 1, window=output_win)\n",
    "            del data, mean_tile, max_tile\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        # Phase 2: Std\n",
    "        print(\"\\nPhase 2/2: Std Aggregation\")\n",
    "        for input_win, output_win in tqdm(windows, desc=\"Std\"):\n",
    "            data = src.read(1, window=input_win)\n",
    "            std_tile = resample_tile_std(data, scale_factor)\n",
    "            datasets['std'].write(std_tile, 1, window=output_win)\n",
    "            del data, std_tile\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        # Dateien schließen\n",
    "        for key, ds in datasets.items():\n",
    "            ds.close()\n",
    "            stats['output_files'][key] = str(output_paths[key].name)\n",
    "        \n",
    "        print(\"\\n✓ Verarbeitung abgeschlossen\")\n",
    "        print(f\"  Mean: {output_paths['mean'].name}\")\n",
    "        print(f\"  Max:  {output_paths['max'].name}\")\n",
    "        print(f\"  Std:  {output_paths['std'].name}\")\n",
    "    \n",
    "    stats['end_time'] = datetime.now().isoformat()\n",
    "    return stats\n",
    "\n",
    "\n",
    "print(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc44991",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. CONFIGURATION & PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c1e3b",
   "metadata": {},
   "source": [
    "### 3.1 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89063c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"/content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit\")\n",
    "DATA_DIR = BASE_DIR / 'data' / 'CHM'\n",
    "INPUT_DIR = DATA_DIR / 'processed'\n",
    "OUTPUT_DIR = DATA_DIR / 'processed' / 'CHM_10m'\n",
    "VALIDATION_DIR = OUTPUT_DIR / 'validation'\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "VALIDATION_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"✓ Base directory: {BASE_DIR}\")\n",
    "print(f\"✓ Input directory: {INPUT_DIR}\")\n",
    "print(f\"✓ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"✓ Validation directory: {VALIDATION_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c956e88",
   "metadata": {},
   "source": [
    "### 3.2 Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4950fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSING_PARAMS = {\n",
    "    # Cities to process\n",
    "    'cities': ['Berlin', 'Hamburg', 'Rostock'],\n",
    "    \n",
    "    # Resampling parameters\n",
    "    'scale_factor': 10,      # 1m → 10m\n",
    "    'tile_size': 512,        # Kachelgröße in Pixeln (1m Auflösung)\n",
    "                             # 512×512 = ~1MB Float32, nach Resampling 51×51 = ~10KB\n",
    "    'nodata_value': -9999,   # NoData-Wert für CHM-Daten\n",
    "    \n",
    "    # Aggregation methods\n",
    "    'aggregations': ['mean', 'max', 'std'],\n",
    "    \n",
    "    # Output settings\n",
    "    'compression': 'lzw',\n",
    "    'dtype': 'float32'\n",
    "}\n",
    "\n",
    "# Display parameters\n",
    "print(\"Processing Parameters:\")\n",
    "print(\"-\" * 50)\n",
    "for key, value in PROCESSING_PARAMS.items():\n",
    "    print(f\"  {key:<25} {str(value):<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce122a4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. DATA LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87694c1",
   "metadata": {},
   "source": [
    "### 4.1 Load Input Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe72a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CHM input files...\\n\")\n",
    "\n",
    "input_files = {}\n",
    "for city in PROCESSING_PARAMS['cities']:\n",
    "    input_path = INPUT_DIR / f\"CHM_1m_{city}.tif\"\n",
    "    \n",
    "    if not input_path.exists():\n",
    "        print(f\"⚠ WARNING: File not found - {input_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    input_files[city] = input_path\n",
    "    print(f\"✓ Found: {input_path.name}\")\n",
    "\n",
    "print(f\"\\n✓ Total files loaded: {len(input_files)}/{len(PROCESSING_PARAMS['cities'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab259ff7",
   "metadata": {},
   "source": [
    "### 4.2 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bad298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating input CHM files...\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "validation_results = {}\n",
    "\n",
    "for city, input_path in input_files.items():\n",
    "    with rasterio.open(input_path) as src:\n",
    "        validation_results[city] = {\n",
    "            'dimensions': f\"{src.height} × {src.width} pixels\",\n",
    "            'resolution': f\"{src.res[0]:.1f}m × {src.res[1]:.1f}m\",\n",
    "            'crs': str(src.crs),\n",
    "            'dtype': str(src.dtypes[0]),\n",
    "            'nodata': src.nodata\n",
    "        }\n",
    "        \n",
    "        print(f\"{city:10} | Dim: {validation_results[city]['dimensions']:20} | \"\n",
    "              f\"Res: {validation_results[city]['resolution']:15} | \"\n",
    "              f\"CRS: {validation_results[city]['crs']}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"✓ All input files validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e20efb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. MAIN PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc6910",
   "metadata": {},
   "source": [
    "### 5.1 Windowed Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b86d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STARTING CHM RESAMPLING: 1m → 10m\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "for city, input_path in input_files.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING: {city}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Define output paths\n",
    "    output_paths = {\n",
    "        'mean': OUTPUT_DIR / f\"CHM_10m_mean_{city}.tif\",\n",
    "        'max': OUTPUT_DIR / f\"CHM_10m_max_{city}.tif\",\n",
    "        'std': OUTPUT_DIR / f\"CHM_10m_std_{city}.tif\"\n",
    "    }\n",
    "    \n",
    "    # Process resampling\n",
    "    stats = resample_chm_windowed(\n",
    "        input_path=input_path,\n",
    "        output_paths=output_paths,\n",
    "        tile_size=PROCESSING_PARAMS['tile_size'],\n",
    "        scale_factor=PROCESSING_PARAMS['scale_factor']\n",
    "    )\n",
    "    \n",
    "    all_stats[city] = stats\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"✓ ALL CITIES PROCESSED SUCCESSFULLY\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ed2b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. RESULTS & OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77ed00",
   "metadata": {},
   "source": [
    "### 6.1 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d41d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for city, stats in all_stats.items():\n",
    "    print(f\"\\n{city}:\")\n",
    "    print(f\"  Input File:    {stats['input_file']}\")\n",
    "    print(f\"  Tiles Processed: {stats['tile_count']}\")\n",
    "    print(f\"  Output Files:\")\n",
    "    for agg_type, filename in stats['output_files'].items():\n",
    "        print(f\"    - {agg_type.upper():6}: {filename}\")\n",
    "    \n",
    "    summary_data.append({\n",
    "        'city': city,\n",
    "        'tiles': stats['tile_count'],\n",
    "        'files_generated': len(stats['output_files'])\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total Cities Processed: {len(all_stats)}\")\n",
    "print(f\"Total Output Files: {sum(s['files_generated'] for s in summary_data)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9c98c",
   "metadata": {},
   "source": [
    "### 6.2 Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd20b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processing statistics to JSON\n",
    "stats_file = VALIDATION_DIR / 'processing_stats.json'\n",
    "\n",
    "export_data = {\n",
    "    'processing_date': datetime.now().isoformat(),\n",
    "    'parameters': PROCESSING_PARAMS,\n",
    "    'cities': all_stats\n",
    "}\n",
    "\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(f\"✓ Processing statistics exported: {stats_file.name}\")\n",
    "\n",
    "# List all generated output files\n",
    "print(\"\\n✓ Generated Output Files:\")\n",
    "print(\"-\" * 80)\n",
    "for output_file in sorted(OUTPUT_DIR.glob('CHM_10m_*.tif')):\n",
    "    file_size = output_file.stat().st_size / (1024**2)  # Convert to MB\n",
    "    print(f\"  {output_file.name:<30} ({file_size:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc620ef",
   "metadata": {},
   "source": [
    "### 6.3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8975c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating validation visualizations...\\n\")\n",
    "\n",
    "# Visualization 1: Tile count comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "cities_list = list(all_stats.keys())\n",
    "tile_counts = [all_stats[city]['tile_count'] for city in cities_list]\n",
    "\n",
    "bars = ax.bar(cities_list, tile_counts, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('City', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Tiles Processed', fontsize=12, fontweight='bold')\n",
    "ax.set_title('CHM Resampling: Tile Count per City', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(VALIDATION_DIR / 'tile_count_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization 1: Tile count comparison saved\")\n",
    "\n",
    "# Visualization 2: Sample CHM comparison (if available)\n",
    "# This would show a side-by-side comparison of 1m vs 10m resolution\n",
    "# You can expand this section to add more specific visualizations\n",
    "\n",
    "print(\"\\n✓ All visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a0449",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. SUMMARY & INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca886a2",
   "metadata": {},
   "source": [
    "### 7.1 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab60cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOK COMPLETE - KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PROCESSING SUMMARY:\")\n",
    "print(f\"   - Cities processed: {len(all_stats)}\")\n",
    "print(f\"   - Total output files: {sum(len(stats['output_files']) for stats in all_stats.values())}\")\n",
    "print(f\"   - Aggregation methods: {', '.join(PROCESSING_PARAMS['aggregations'])}\")\n",
    "\n",
    "print(\"\\n2. RESOLUTION TRANSFORMATION:\")\n",
    "print(f\"   - Input resolution: 1m × 1m\")\n",
    "print(f\"   - Output resolution: 10m × 10m\")\n",
    "print(f\"   - Scale factor: {PROCESSING_PARAMS['scale_factor']}\")\n",
    "\n",
    "print(\"\\n3. MEMORY OPTIMIZATION:\")\n",
    "print(f\"   - Tile size: {PROCESSING_PARAMS['tile_size']}×{PROCESSING_PARAMS['tile_size']} pixels\")\n",
    "print(f\"   - Windowed processing: Sequential aggregation (mean+max → std)\")\n",
    "print(f\"   - RAM usage: ~1-2GB (vs. 6-8GB for full raster approach)\")\n",
    "\n",
    "print(\"\\n4. OUTPUT FILES LOCATION:\")\n",
    "print(f\"   - CHM 10m rasters: {OUTPUT_DIR}\")\n",
    "print(f\"   - Validation reports: {VALIDATION_DIR}\")\n",
    "\n",
    "print(\"\\n5. NEXT STEPS:\")\n",
    "print(\"   → Use CHM_10m_mean for average canopy height features\")\n",
    "print(\"   → Use CHM_10m_max for maximum height detection\")\n",
    "print(\"   → Use CHM_10m_std for canopy height variability\")\n",
    "print(\"   → Align with Sentinel-2 10m resolution for feature extraction\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ CHM RESAMPLING PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa28aa1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Notebook End**\n",
    "\n",
    "Exported: 2025-01-08\n",
    "\n",
    "Author: Silas Pignotti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
