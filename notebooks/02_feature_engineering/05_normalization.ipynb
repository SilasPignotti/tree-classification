{"cells":[{"cell_type":"markdown","metadata":{"id":"NPhfSC6z4k-4"},"source":["# Phase 5: Feature Normalisierung & Model-Ready Export\n","\n","**Ziel:** Features standardisieren ohne Data Leakage\n","\n","**Input:**\n","- `data/splits/*.gpkg` (6 Dateien aus Phase 4 mit 184 Features pro Baum)\n","\n","**Output:**\n","- `data/model_ready/experiment_0_1_single_city/` (Hamburg/Berlin Single-City)\n","- `data/model_ready/experiment_2_cross_city/` (Hamburg+Berlin ‚Üí Rostock Zero-Shot)\n","- `data/model_ready/experiment_3_finetuning/` (Fine-Tuning Eval)\n","- `feature_names.json`, `label_encoder.pkl`\n","\n","**Methodik:**\n","- StandardScaler (Mean=0, Std=1)\n","- Experiment-spezifische Scaler (kein Leakage!)\n","- Label Encoding: Genus ‚Üí Numerisch (0-6)"]},{"cell_type":"markdown","metadata":{"id":"zbhAOyV94k-9"},"source":["## 1. Setup: Google Drive Mount + Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtqCQvvV4k--","executionInfo":{"status":"ok","timestamp":1767712689569,"user_tz":-60,"elapsed":16281,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"c233fbbf-fe91-4ef5-e241-16237a3c2c3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQJmQUAh4k-_","executionInfo":{"status":"ok","timestamp":1767712730445,"user_tz":-60,"elapsed":1349,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"a9ab5a6d-f86b-4224-dfb5-40d7ae414493"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Imports erfolgreich\n"]}],"source":["# Imports\n","import geopandas as gpd\n","import pandas as pd\n","import numpy as np\n","import json\n","import pickle\n","from pathlib import Path\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print('‚úÖ Imports erfolgreich')"]},{"cell_type":"markdown","metadata":{"id":"8S4NOICp4k-_"},"source":["## 2. Konfiguration"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5V5ciiF4k_A","executionInfo":{"status":"ok","timestamp":1767712763941,"user_tz":-60,"elapsed":1133,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"8c98f2a8-2579-447d-859d-da8d73ad9ff7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Konfiguration:\n","  Drive Root: /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit\n","  Viable Genera: 7 (['TILIA', 'ACER', 'QUERCUS', 'FRAXINUS', 'BETULA', 'SORBUS', 'PRUNUS'])\n","  Expected Features: 184\n"]}],"source":["DRIVE_ROOT = Path(\"/content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit\")\n","\n","# Input-Pfade\n","SPLITS_DIR = DRIVE_ROOT / 'data' / 'splits'\n","\n","# Output-Pfade\n","MODEL_READY_DIR = DRIVE_ROOT / 'data' / 'model_ready'\n","MODEL_READY_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Experiment-spezifische Ordner\n","EXP_01_DIR = MODEL_READY_DIR / 'experiment_0_1_single_city'\n","EXP_02_DIR = MODEL_READY_DIR / 'experiment_2_cross_city'\n","EXP_03_DIR = MODEL_READY_DIR / 'experiment_3_finetuning'\n","\n","for d in [EXP_01_DIR, EXP_02_DIR, EXP_03_DIR]:\n","    d.mkdir(parents=True, exist_ok=True)\n","\n","# Hamburg/Berlin Unterordner f√ºr Exp. 0/1\n","(EXP_01_DIR / 'hamburg').mkdir(exist_ok=True)\n","(EXP_01_DIR / 'berlin').mkdir(exist_ok=True)\n","\n","# Viable Genera (7 Gattungen)\n","VIABLE_GENERA = ['TILIA', 'ACER', 'QUERCUS', 'FRAXINUS', 'BETULA', 'SORBUS', 'PRUNUS']\n","\n","# Feature-Anzahl (184 = 180 S2 + 4 CHM)\n","N_FEATURES = 184\n","\n","print(f'Konfiguration:')\n","print(f'  Drive Root: {DRIVE_ROOT}')\n","print(f'  Viable Genera: {len(VIABLE_GENERA)} ({VIABLE_GENERA})')\n","print(f'  Expected Features: {N_FEATURES}')"]},{"cell_type":"markdown","metadata":{"id":"nvavPxBp4k_A"},"source":["## 3. Hilfsfunktionen"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOO_0cbo4k_B","executionInfo":{"status":"ok","timestamp":1767712770196,"user_tz":-60,"elapsed":31,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"6438de99-cbcf-4727-c098-c23f21886a80"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Hilfsfunktionen definiert\n"]}],"source":["def load_split_data(filename):\n","    \"\"\"\n","    L√§dt Split-Datei und extrahiert Features + Labels.\n","\n","    Args:\n","        filename: Name der GPKG-Datei (z.B. 'hamburg_train.gpkg')\n","\n","    Returns:\n","        X: Feature-Matrix (n_samples, 184)\n","        y: Label-Array (n_samples,) als Genus-Namen\n","        gdf: Original GeoDataFrame\n","    \"\"\"\n","    path = SPLITS_DIR / filename\n","    print(f'  Lade {filename}...')\n","\n","    gdf = gpd.read_file(path)\n","\n","    # Feature-Spalten: Alle numerischen au√üer tree_id, city, genus_latin, geometry, block_id\n","    exclude_cols = ['tree_id', 'city', 'genus_latin', 'geometry', 'block_id']\n","    feature_cols = [col for col in gdf.columns if col not in exclude_cols and gdf[col].dtype in ['float64', 'int64', 'float32', 'int32']]\n","\n","    # Validierung\n","    if len(feature_cols) != N_FEATURES:\n","        print(f'    ‚ö†Ô∏è  WARNING: Erwartet {N_FEATURES} Features, gefunden {len(feature_cols)}')\n","\n","    # Features extrahieren\n","    X = gdf[feature_cols].values.astype(np.float32)\n","\n","    # Labels extrahieren\n","    y = gdf['genus_latin'].values\n","\n","    print(f'    ‚úÖ {len(gdf):,} Samples, {X.shape[1]} Features')\n","\n","    return X, y, gdf, feature_cols\n","\n","\n","def save_arrays(output_dir, X_train, y_train, X_val, y_val, scaler, suffix=''):\n","    \"\"\"\n","    Speichert NumPy Arrays und Scaler.\n","\n","    Args:\n","        output_dir: Zielverzeichnis\n","        X_train, y_train, X_val, y_val: Arrays\n","        scaler: Fitted StandardScaler\n","        suffix: Optional suffix f√ºr Dateinamen (z.B. '_hamburg')\n","    \"\"\"\n","    output_dir = Path(output_dir)\n","\n","    np.save(output_dir / f'X_train{suffix}.npy', X_train)\n","    np.save(output_dir / f'y_train{suffix}.npy', y_train)\n","    np.save(output_dir / f'X_val{suffix}.npy', X_val)\n","    np.save(output_dir / f'y_val{suffix}.npy', y_val)\n","\n","    with open(output_dir / 'scaler.pkl', 'wb') as f:\n","        pickle.dump(scaler, f)\n","\n","    print(f'    ‚úÖ Gespeichert in {output_dir}')\n","\n","\n","def save_test_arrays(output_dir, X_test, y_test, suffix=''):\n","    \"\"\"\n","    Speichert Test-Arrays.\n","    \"\"\"\n","    output_dir = Path(output_dir)\n","\n","    np.save(output_dir / f'X_test{suffix}.npy', X_test)\n","    np.save(output_dir / f'y_test{suffix}.npy', y_test)\n","\n","    print(f'    ‚úÖ Test-Arrays gespeichert in {output_dir}')\n","\n","\n","print('‚úÖ Hilfsfunktionen definiert')"]},{"cell_type":"markdown","metadata":{"id":"BDZQNQ194k_B"},"source":["## 4. Daten laden"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIWdl8wA4k_C","executionInfo":{"status":"ok","timestamp":1767712799060,"user_tz":-60,"elapsed":23405,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"ac022633-f608-47d6-a755-d0765ff96171"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== LADE SPLIT-DATEN ===\n","\n","Hamburg:\n","  Lade hamburg_train.gpkg...\n","    ‚úÖ 8,371 Samples, 184 Features\n","  Lade hamburg_val.gpkg...\n","    ‚úÖ 2,129 Samples, 184 Features\n","\n","Berlin:\n","  Lade berlin_train.gpkg...\n","    ‚úÖ 8,299 Samples, 184 Features\n","  Lade berlin_val.gpkg...\n","    ‚úÖ 1,989 Samples, 184 Features\n","\n","Rostock:\n","  Lade rostock_zero_shot.gpkg...\n","    ‚úÖ 6,675 Samples, 184 Features\n","  Lade rostock_finetune_eval.gpkg...\n","    ‚úÖ 1,403 Samples, 184 Features\n","\n","‚úÖ Alle Daten geladen\n"]}],"source":["print('=== LADE SPLIT-DATEN ===')\n","\n","# Hamburg\n","print('\\nHamburg:')\n","X_train_hh, y_train_hh, _, feature_cols = load_split_data('hamburg_train.gpkg')\n","X_val_hh, y_val_hh, _, _ = load_split_data('hamburg_val.gpkg')\n","\n","# Berlin\n","print('\\nBerlin:')\n","X_train_be, y_train_be, _, _ = load_split_data('berlin_train.gpkg')\n","X_val_be, y_val_be, _, _ = load_split_data('berlin_val.gpkg')\n","\n","# Rostock\n","print('\\nRostock:')\n","X_test_rostock_zs, y_test_rostock_zs, _, _ = load_split_data('rostock_zero_shot.gpkg')\n","X_test_rostock_ft, y_test_rostock_ft, _, _ = load_split_data('rostock_finetune_eval.gpkg')\n","\n","print('\\n‚úÖ Alle Daten geladen')"]},{"cell_type":"markdown","metadata":{"id":"7HTLT1E34k_C"},"source":["## 5. Label Encoding\n","\n","**Wichtig:** Label Encoder wird einmal auf allen viable Genera gefittet (nicht nur auf Train)."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U58Q37Yi4k_C","executionInfo":{"status":"ok","timestamp":1767712808628,"user_tz":-60,"elapsed":16,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"6c168d4a-14d1-4e0a-c0fb-e9848cbfe103"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== LABEL ENCODING ===\n","\n","Label Mapping:\n","  0: ACER\n","  1: BETULA\n","  2: FRAXINUS\n","  3: PRUNUS\n","  4: QUERCUS\n","  5: SORBUS\n","  6: TILIA\n","\n","Transformiere Labels...\n","‚úÖ Label Encoding abgeschlossen\n"]}],"source":["print('=== LABEL ENCODING ===')\n","\n","# Label Encoder fitten\n","label_encoder = LabelEncoder()\n","label_encoder.fit(VIABLE_GENERA)\n","\n","print(f'\\nLabel Mapping:')\n","for i, genus in enumerate(label_encoder.classes_):\n","    print(f'  {i}: {genus}')\n","\n","# Transformiere alle Labels\n","print('\\nTransformiere Labels...')\n","y_train_hh = label_encoder.transform(y_train_hh)\n","y_val_hh = label_encoder.transform(y_val_hh)\n","y_train_be = label_encoder.transform(y_train_be)\n","y_val_be = label_encoder.transform(y_val_be)\n","y_test_rostock_zs = label_encoder.transform(y_test_rostock_zs)\n","y_test_rostock_ft = label_encoder.transform(y_test_rostock_ft)\n","\n","# Speichere Label Encoder\n","with open(MODEL_READY_DIR / 'label_encoder.pkl', 'wb') as f:\n","    pickle.dump(label_encoder, f)\n","\n","print('‚úÖ Label Encoding abgeschlossen')"]},{"cell_type":"markdown","metadata":{"id":"8hTyPRbJ4k_D"},"source":["## 6. Validierung: Label Distribution"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKf2B5qC4k_D","executionInfo":{"status":"ok","timestamp":1767712815132,"user_tz":-60,"elapsed":34,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"86104546-4696-4480-92d9-12cefea6f2e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== CHECK: Label Distribution ===\n","\n","Hamburg Train:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 1,192 (14.2%)\n","    BETULA: 1,217 (14.5%)\n","    FRAXINUS: 1,157 (13.8%)\n","    PRUNUS: 1,194 (14.3%)\n","    QUERCUS: 1,200 (14.3%)\n","    SORBUS: 1,205 (14.4%)\n","    TILIA: 1,206 (14.4%)\n","\n","Hamburg Val:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 308 (14.5%)\n","    BETULA: 283 (13.3%)\n","    FRAXINUS: 343 (16.1%)\n","    PRUNUS: 306 (14.4%)\n","    QUERCUS: 300 (14.1%)\n","    SORBUS: 295 (13.9%)\n","    TILIA: 294 (13.8%)\n","\n","Berlin Train:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 1,224 (14.7%)\n","    BETULA: 1,198 (14.4%)\n","    FRAXINUS: 1,239 (14.9%)\n","    PRUNUS: 1,184 (14.3%)\n","    QUERCUS: 1,226 (14.8%)\n","    SORBUS: 1,026 (12.4%)\n","    TILIA: 1,202 (14.5%)\n","\n","Berlin Val:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 276 (13.9%)\n","    BETULA: 302 (15.2%)\n","    FRAXINUS: 261 (13.1%)\n","    PRUNUS: 316 (15.9%)\n","    QUERCUS: 274 (13.8%)\n","    SORBUS: 262 (13.2%)\n","    TILIA: 298 (15.0%)\n","\n","Rostock Zero-Shot:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 1,227 (18.4%)\n","    BETULA: 1,286 (19.3%)\n","    FRAXINUS: 730 (10.9%)\n","    PRUNUS: 546 (8.2%)\n","    QUERCUS: 1,199 (18.0%)\n","    SORBUS: 524 (7.9%)\n","    TILIA: 1,163 (17.4%)\n","\n","Rostock Fine-Tune Eval:\n","  Gattungen vorhanden: 7/7\n","  Verteilung:\n","    ACER: 273 (19.5%)\n","    BETULA: 214 (15.3%)\n","    FRAXINUS: 116 (8.3%)\n","    PRUNUS: 79 (5.6%)\n","    QUERCUS: 263 (18.7%)\n","    SORBUS: 121 (8.6%)\n","    TILIA: 337 (24.0%)\n"]}],"source":["print('=== CHECK: Label Distribution ===')\n","\n","def check_labels(y, name):\n","    unique_labels = np.unique(y)\n","    counts = pd.Series(y).value_counts().sort_index()\n","    print(f'\\n{name}:')\n","    print(f'  Gattungen vorhanden: {len(unique_labels)}/{len(VIABLE_GENERA)}')\n","    if len(unique_labels) < len(VIABLE_GENERA):\n","        missing = set(range(len(VIABLE_GENERA))) - set(unique_labels)\n","        print(f'  ‚ö†Ô∏è  Fehlende Gattungen: {[VIABLE_GENERA[i] for i in missing]}')\n","    print(f'  Verteilung:')\n","    for label, count in counts.items():\n","        genus_name = label_encoder.inverse_transform([label])[0]\n","        print(f'    {genus_name}: {count:,} ({count/len(y)*100:.1f}%)')\n","\n","check_labels(y_train_hh, 'Hamburg Train')\n","check_labels(y_val_hh, 'Hamburg Val')\n","check_labels(y_train_be, 'Berlin Train')\n","check_labels(y_val_be, 'Berlin Val')\n","check_labels(y_test_rostock_zs, 'Rostock Zero-Shot')\n","check_labels(y_test_rostock_ft, 'Rostock Fine-Tune Eval')"]},{"cell_type":"markdown","metadata":{"id":"TFtdNeOY4k_D"},"source":["## 7. Normalisierung: Experiment 0/1 - Hamburg Single-City"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKsf9Jom4k_E","executionInfo":{"status":"ok","timestamp":1767712829247,"user_tz":-60,"elapsed":100,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"371a2ec0-3c83-4d16-e439-22a5aaa8e22f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== EXPERIMENT 0/1: Hamburg Single-City ===\n","\n","Train (nach Skalierung):\n","  Mean: -0.0000 (sollte ~0 sein)\n","  Std:  1.0000 (sollte ~1 sein)\n","\n","Val (nach Skalierung):\n","  Mean: 0.0148 (kann ‚â† 0 sein)\n","  Std:  1.9760 (kann ‚â† 1 sein)\n","    ‚úÖ Gespeichert in /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/experiment_0_1_single_city/hamburg\n","\n","‚úÖ Hamburg Single-City abgeschlossen\n"]}],"source":["print('\\n=== EXPERIMENT 0/1: Hamburg Single-City ===')\n","\n","# Scaler auf Hamburg Train fitten\n","scaler_hamburg = StandardScaler()\n","scaler_hamburg.fit(X_train_hh)\n","\n","# Transformiere Hamburg Train/Val\n","X_train_hh_scaled = scaler_hamburg.transform(X_train_hh)\n","X_val_hh_scaled = scaler_hamburg.transform(X_val_hh)\n","\n","# Statistiken\n","print('\\nTrain (nach Skalierung):')\n","print(f'  Mean: {X_train_hh_scaled.mean():.4f} (sollte ~0 sein)')\n","print(f'  Std:  {X_train_hh_scaled.std():.4f} (sollte ~1 sein)')\n","\n","print('\\nVal (nach Skalierung):')\n","print(f'  Mean: {X_val_hh_scaled.mean():.4f} (kann ‚â† 0 sein)')\n","print(f'  Std:  {X_val_hh_scaled.std():.4f} (kann ‚â† 1 sein)')\n","\n","# Speichern\n","output_dir = EXP_01_DIR / 'hamburg'\n","save_arrays(output_dir, X_train_hh_scaled, y_train_hh, X_val_hh_scaled, y_val_hh, scaler_hamburg)\n","\n","print('\\n‚úÖ Hamburg Single-City abgeschlossen')"]},{"cell_type":"markdown","metadata":{"id":"V9Kne47x4k_E"},"source":["## 8. Normalisierung: Experiment 0/1 - Berlin Single-City"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qp677464k_E","executionInfo":{"status":"ok","timestamp":1767712849826,"user_tz":-60,"elapsed":61,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"3b1dbc02-594d-40d1-9b60-faf919be54d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== EXPERIMENT 0/1: Berlin Single-City ===\n","\n","Train (nach Skalierung):\n","  Mean: -0.0000 (sollte ~0 sein)\n","  Std:  1.0000 (sollte ~1 sein)\n","\n","Val (nach Skalierung):\n","  Mean: -0.0382 (kann ‚â† 0 sein)\n","  Std:  1.0143 (kann ‚â† 1 sein)\n","    ‚úÖ Gespeichert in /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/experiment_0_1_single_city/berlin\n","\n","‚úÖ Berlin Single-City abgeschlossen\n"]}],"source":["print('\\n=== EXPERIMENT 0/1: Berlin Single-City ===')\n","\n","# Scaler auf Berlin Train fitten\n","scaler_berlin = StandardScaler()\n","scaler_berlin.fit(X_train_be)\n","\n","# Transformiere Berlin Train/Val\n","X_train_be_scaled = scaler_berlin.transform(X_train_be)\n","X_val_be_scaled = scaler_berlin.transform(X_val_be)\n","\n","# Statistiken\n","print('\\nTrain (nach Skalierung):')\n","print(f'  Mean: {X_train_be_scaled.mean():.4f} (sollte ~0 sein)')\n","print(f'  Std:  {X_train_be_scaled.std():.4f} (sollte ~1 sein)')\n","\n","print('\\nVal (nach Skalierung):')\n","print(f'  Mean: {X_val_be_scaled.mean():.4f} (kann ‚â† 0 sein)')\n","print(f'  Std:  {X_val_be_scaled.std():.4f} (kann ‚â† 1 sein)')\n","\n","# Speichern\n","output_dir = EXP_01_DIR / 'berlin'\n","save_arrays(output_dir, X_train_be_scaled, y_train_be, X_val_be_scaled, y_val_be, scaler_berlin)\n","\n","print('\\n‚úÖ Berlin Single-City abgeschlossen')"]},{"cell_type":"markdown","metadata":{"id":"Td-Nok4s4k_F"},"source":["## 9. Normalisierung: Experiment 2 - Cross-City Transfer (Hamburg+Berlin ‚Üí Rostock)\n","\n","**Kritisch:** Scaler wird auf Hamburg+Berlin COMBINED gefittet!"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drcOIVzR4k_F","executionInfo":{"status":"ok","timestamp":1767712868054,"user_tz":-60,"elapsed":149,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"30a10726-325d-485c-939e-f06b4a8068e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== EXPERIMENT 2: Cross-City Transfer (Hamburg+Berlin ‚Üí Rostock) ===\n","\n","Combined Train: 16,670 Samples\n","\n","Transformiere...\n","\n","Train Combined (nach Skalierung):\n","  Mean: -0.0000 (sollte ~0 sein)\n","  Std:  1.0000 (sollte ~1 sein)\n","\n","Rostock Zero-Shot Test (nach Skalierung):\n","  Mean: 0.1568 (kann ‚â† 0 sein)\n","  Std:  1.0341 (kann ‚â† 1 sein)\n","\n","Speichere...\n","  ‚úÖ Gespeichert in /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/experiment_2_cross_city\n","\n","‚úÖ Cross-City Transfer abgeschlossen\n"]}],"source":["print('\\n=== EXPERIMENT 2: Cross-City Transfer (Hamburg+Berlin ‚Üí Rostock) ===')\n","\n","# Kombiniere Hamburg + Berlin Train\n","X_train_combined = np.vstack([X_train_hh, X_train_be])\n","print(f'\\nCombined Train: {X_train_combined.shape[0]:,} Samples')\n","\n","# Scaler auf Combined Train fitten\n","scaler_cross_city = StandardScaler()\n","scaler_cross_city.fit(X_train_combined)\n","\n","# Transformiere alle Splits\n","print('\\nTransformiere...')\n","X_train_hh_cc = scaler_cross_city.transform(X_train_hh)\n","X_train_be_cc = scaler_cross_city.transform(X_train_be)\n","X_val_hh_cc = scaler_cross_city.transform(X_val_hh)\n","X_val_be_cc = scaler_cross_city.transform(X_val_be)\n","X_test_rostock_zs_scaled = scaler_cross_city.transform(X_test_rostock_zs)\n","\n","# Statistiken\n","print('\\nTrain Combined (nach Skalierung):')\n","X_train_combined_scaled = np.vstack([X_train_hh_cc, X_train_be_cc])\n","print(f'  Mean: {X_train_combined_scaled.mean():.4f} (sollte ~0 sein)')\n","print(f'  Std:  {X_train_combined_scaled.std():.4f} (sollte ~1 sein)')\n","\n","print('\\nRostock Zero-Shot Test (nach Skalierung):')\n","print(f'  Mean: {X_test_rostock_zs_scaled.mean():.4f} (kann ‚â† 0 sein)')\n","print(f'  Std:  {X_test_rostock_zs_scaled.std():.4f} (kann ‚â† 1 sein)')\n","\n","# Speichern\n","print('\\nSpeichere...')\n","np.save(EXP_02_DIR / 'X_train_hamburg.npy', X_train_hh_cc)\n","np.save(EXP_02_DIR / 'y_train_hamburg.npy', y_train_hh)\n","np.save(EXP_02_DIR / 'X_train_berlin.npy', X_train_be_cc)\n","np.save(EXP_02_DIR / 'y_train_berlin.npy', y_train_be)\n","np.save(EXP_02_DIR / 'X_val_hamburg.npy', X_val_hh_cc)\n","np.save(EXP_02_DIR / 'y_val_hamburg.npy', y_val_hh)\n","np.save(EXP_02_DIR / 'X_val_berlin.npy', X_val_be_cc)\n","np.save(EXP_02_DIR / 'y_val_berlin.npy', y_val_be)\n","np.save(EXP_02_DIR / 'X_test_rostock_zero_shot.npy', X_test_rostock_zs_scaled)\n","np.save(EXP_02_DIR / 'y_test_rostock_zero_shot.npy', y_test_rostock_zs)\n","\n","with open(EXP_02_DIR / 'scaler.pkl', 'wb') as f:\n","    pickle.dump(scaler_cross_city, f)\n","\n","print(f'  ‚úÖ Gespeichert in {EXP_02_DIR}')\n","\n","print('\\n‚úÖ Cross-City Transfer abgeschlossen')"]},{"cell_type":"markdown","metadata":{"id":"cqjrtrVw4k_F"},"source":["## 10. Normalisierung: Experiment 3 - Fine-Tuning Eval\n","\n","**Wichtig:** Nutzt denselben Scaler wie Exp. 2 (scaler_cross_city)!"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEH31_xR4k_F","executionInfo":{"status":"ok","timestamp":1767712879594,"user_tz":-60,"elapsed":113,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"50681767-87d1-4a78-e03f-b4b3d5011270"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== EXPERIMENT 3: Fine-Tuning Eval ===\n","\n","Rostock Fine-Tuning Eval (nach Skalierung):\n","  Mean: 0.1621\n","  Std:  1.0837\n","\n","Speichere...\n","  ‚úÖ Gespeichert in /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/experiment_3_finetuning\n","  ‚ÑπÔ∏è  Nutzt denselben Scaler wie Exp. 2 (scaler_cross_city)\n","\n","‚úÖ Fine-Tuning Eval abgeschlossen\n"]}],"source":["print('\\n=== EXPERIMENT 3: Fine-Tuning Eval ===')\n","\n","# Transformiere Rostock Fine-Tuning Eval mit Cross-City Scaler\n","X_test_rostock_ft_scaled = scaler_cross_city.transform(X_test_rostock_ft)\n","\n","# Statistiken\n","print('\\nRostock Fine-Tuning Eval (nach Skalierung):')\n","print(f'  Mean: {X_test_rostock_ft_scaled.mean():.4f}')\n","print(f'  Std:  {X_test_rostock_ft_scaled.std():.4f}')\n","\n","# Speichern\n","print('\\nSpeichere...')\n","np.save(EXP_03_DIR / 'X_test_rostock_finetune_eval.npy', X_test_rostock_ft_scaled)\n","np.save(EXP_03_DIR / 'y_test_rostock_finetune_eval.npy', y_test_rostock_ft)\n","\n","# Symlink zu Exp. 2 Scaler (oder kopieren)\n","import shutil\n","shutil.copy(EXP_02_DIR / 'scaler.pkl', EXP_03_DIR / 'scaler.pkl')\n","\n","print(f'  ‚úÖ Gespeichert in {EXP_03_DIR}')\n","print('  ‚ÑπÔ∏è  Nutzt denselben Scaler wie Exp. 2 (scaler_cross_city)')\n","\n","print('\\n‚úÖ Fine-Tuning Eval abgeschlossen')"]},{"cell_type":"markdown","metadata":{"id":"NtQyDjAG4k_G"},"source":["## 11. Export: Feature Names & Metadaten"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzTLXcxG4k_G","executionInfo":{"status":"ok","timestamp":1767712886752,"user_tz":-60,"elapsed":37,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"ad377c17-8c77-4c5c-c084-4e9fb7ef5e17"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== EXPORT: Feature Names & Metadaten ===\n","‚úÖ Feature Metadata gespeichert: /content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/feature_names.json\n","   184 Features total\n","   - Sentinel-2 Bands: 120\n","   - Vegetation Indices: 60\n","   - CHM Features: 4\n"]}],"source":["print('\\n=== EXPORT: Feature Names & Metadaten ===')\n","\n","# Feature Names\n","feature_metadata = {\n","    'n_features': len(feature_cols),\n","    'feature_names': feature_cols,\n","    'feature_groups': {\n","        'sentinel2_bands': [col for col in feature_cols if any(band in col for band in ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12'])],\n","        'vegetation_indices': [col for col in feature_cols if any(idx in col for idx in ['NDre', 'NDVIre', 'kNDVI', 'VARI', 'RTVIcore'])],\n","        'chm_features': [col for col in feature_cols if 'CHM' in col or col == 'height_m']\n","    },\n","    'viable_genera': VIABLE_GENERA,\n","    'n_classes': len(VIABLE_GENERA)\n","}\n","\n","# Speichern\n","with open(MODEL_READY_DIR / 'feature_names.json', 'w') as f:\n","    json.dump(feature_metadata, f, indent=2)\n","\n","print(f'‚úÖ Feature Metadata gespeichert: {MODEL_READY_DIR / \"feature_names.json\"}')\n","print(f'   {feature_metadata[\"n_features\"]} Features total')\n","print(f'   - Sentinel-2 Bands: {len(feature_metadata[\"feature_groups\"][\"sentinel2_bands\"])}')\n","print(f'   - Vegetation Indices: {len(feature_metadata[\"feature_groups\"][\"vegetation_indices\"])}')\n","print(f'   - CHM Features: {len(feature_metadata[\"feature_groups\"][\"chm_features\"])}')"]},{"cell_type":"markdown","metadata":{"id":"lpbjiBky4k_G"},"source":["## 12. Validierung: Shape & Konsistenz"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HstaJYqO4k_G","executionInfo":{"status":"ok","timestamp":1767712894272,"user_tz":-60,"elapsed":43,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"2d651081-e4a3-4ae8-872e-50612bc82101"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL VALIDATION: Shape & Konsistenz ===\n","\n","Hamburg Train:\n","  X Shape: (8371, 184)\n","  y Shape: (8371,)\n","  ‚úÖ Validation passed\n","\n","Hamburg Val:\n","  X Shape: (2129, 184)\n","  y Shape: (2129,)\n","  ‚úÖ Validation passed\n","\n","Berlin Train:\n","  X Shape: (8299, 184)\n","  y Shape: (8299,)\n","  ‚úÖ Validation passed\n","\n","Berlin Val:\n","  X Shape: (1989, 184)\n","  y Shape: (1989,)\n","  ‚úÖ Validation passed\n","\n","Rostock Zero-Shot:\n","  X Shape: (6675, 184)\n","  y Shape: (6675,)\n","  ‚úÖ Validation passed\n","\n","Rostock Fine-Tune Eval:\n","  X Shape: (1403, 184)\n","  y Shape: (1403,)\n","  ‚úÖ Validation passed\n","\n","‚úÖ Alle Validierungen bestanden\n"]}],"source":["print('\\n=== FINAL VALIDATION: Shape & Konsistenz ===')\n","\n","def validate_arrays(name, X, y, expected_features=N_FEATURES):\n","    print(f'\\n{name}:')\n","    print(f'  X Shape: {X.shape}')\n","    print(f'  y Shape: {y.shape}')\n","\n","    # Shape Checks\n","    assert X.shape[0] == y.shape[0], f\"‚ùå Sample count mismatch: X={X.shape[0]}, y={y.shape[0]}\"\n","    assert X.shape[1] == expected_features, f\"‚ùå Feature count mismatch: expected {expected_features}, got {X.shape[1]}\"\n","\n","    # NaN Check\n","    if np.isnan(X).any():\n","        print(f\"  ‚ö†Ô∏è  WARNING: {np.isnan(X).sum()} NaN values in X\")\n","\n","    # Label Check\n","    unique_labels = np.unique(y)\n","    if len(unique_labels) < len(VIABLE_GENERA):\n","        print(f\"  ‚ö†Ô∏è  WARNING: Only {len(unique_labels)}/{len(VIABLE_GENERA)} classes present\")\n","\n","    print(f'  ‚úÖ Validation passed')\n","\n","# Experiment 0/1\n","validate_arrays('Hamburg Train', X_train_hh_scaled, y_train_hh)\n","validate_arrays('Hamburg Val', X_val_hh_scaled, y_val_hh)\n","validate_arrays('Berlin Train', X_train_be_scaled, y_train_be)\n","validate_arrays('Berlin Val', X_val_be_scaled, y_val_be)\n","\n","# Experiment 2\n","validate_arrays('Rostock Zero-Shot', X_test_rostock_zs_scaled, y_test_rostock_zs)\n","\n","# Experiment 3\n","validate_arrays('Rostock Fine-Tune Eval', X_test_rostock_ft_scaled, y_test_rostock_ft)\n","\n","print('\\n‚úÖ Alle Validierungen bestanden')"]},{"cell_type":"markdown","metadata":{"id":"rT0i6t1_4k_H"},"source":["## 13. Zusammenfassung"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaTGE6fa4k_H","executionInfo":{"status":"ok","timestamp":1767712950145,"user_tz":-60,"elapsed":35,"user":{"displayName":"Silas P.","userId":"11597691081060335174"}},"outputId":"ae0079e4-81cf-496b-873e-fca65b2214d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","PHASE 5 ABGESCHLOSSEN: Feature Normalisierung & Model-Ready Export\n","======================================================================\n","\n","üìä DATENSATZ-STATISTIK:\n","\n","Experiment 0/1 - Single-City:\n","  Hamburg Train: 8,371 Samples\n","  Hamburg Val:   2,129 Samples\n","  Berlin Train:  8,299 Samples\n","  Berlin Val:    1,989 Samples\n","\n","Experiment 2 - Cross-City Transfer:\n","  Combined Train (HH+BE): 16,670 Samples\n","  Rostock Zero-Shot Test: 6,675 Samples\n","\n","Experiment 3 - Fine-Tuning:\n","  Rostock Fine-Tune Eval: 1,403 Samples\n","\n","üìÅ EXPORTIERTE DATEIEN:\n","\n","/content/drive/MyDrive/Studium/Geoinformation/Module/Projektarbeit/data/model_ready/\n","‚îú‚îÄ‚îÄ experiment_0_1_single_city/\n","‚îÇ   ‚îú‚îÄ‚îÄ hamburg/\n","‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy\n","‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy\n","‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl\n","‚îÇ   ‚îî‚îÄ‚îÄ berlin/\n","‚îÇ       ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy\n","‚îÇ       ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy\n","‚îÇ       ‚îî‚îÄ‚îÄ scaler.pkl\n","‚îú‚îÄ‚îÄ experiment_2_cross_city/\n","‚îÇ   ‚îú‚îÄ‚îÄ X_train_hamburg.npy, y_train_hamburg.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ X_train_berlin.npy, y_train_berlin.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ X_val_hamburg.npy, y_val_hamburg.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ X_val_berlin.npy, y_val_berlin.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ X_test_rostock_zero_shot.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ y_test_rostock_zero_shot.npy\n","‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl (Hamburg+Berlin Combined)\n","‚îú‚îÄ‚îÄ experiment_3_finetuning/\n","‚îÇ   ‚îú‚îÄ‚îÄ X_test_rostock_finetune_eval.npy\n","‚îÇ   ‚îú‚îÄ‚îÄ y_test_rostock_finetune_eval.npy\n","‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl (Copy of Exp. 2)\n","‚îú‚îÄ‚îÄ feature_names.json\n","‚îî‚îÄ‚îÄ label_encoder.pkl\n","\n","üî¨ SCALER-STRATEGIE:\n","  ‚úÖ Hamburg Single-City: Scaler auf Hamburg Train gefittet\n","  ‚úÖ Berlin Single-City: Scaler auf Berlin Train gefittet\n","  ‚úÖ Cross-City (Exp. 2): Scaler auf Hamburg+Berlin Combined gefittet\n","  ‚úÖ Fine-Tuning (Exp. 3): Nutzt Exp. 2 Scaler (kein Leakage!)\n","\n","‚úÖ KEIN DATA LEAKAGE - Scaler immer NUR auf Train gefittet!\n","\n","‚è≠Ô∏è  N√ÑCHSTER SCHRITT: Experiment 0 - RF/CNN Baseline Training\n"]}],"source":["print('\\n' + '='*70)\n","print('PHASE 5 ABGESCHLOSSEN: Feature Normalisierung & Model-Ready Export')\n","print('='*70)\n","\n","print('\\nüìä DATENSATZ-STATISTIK:')\n","\n","print('\\nExperiment 0/1 - Single-City:')\n","print(f'  Hamburg Train: {X_train_hh_scaled.shape[0]:,} Samples')\n","print(f'  Hamburg Val:   {X_val_hh_scaled.shape[0]:,} Samples')\n","print(f'  Berlin Train:  {X_train_be_scaled.shape[0]:,} Samples')\n","print(f'  Berlin Val:    {X_val_be_scaled.shape[0]:,} Samples')\n","\n","print('\\nExperiment 2 - Cross-City Transfer:')\n","print(f'  Combined Train (HH+BE): {X_train_combined_scaled.shape[0]:,} Samples')\n","print(f'  Rostock Zero-Shot Test: {X_test_rostock_zs_scaled.shape[0]:,} Samples')\n","\n","print('\\nExperiment 3 - Fine-Tuning:')\n","print(f'  Rostock Fine-Tune Eval: {X_test_rostock_ft_scaled.shape[0]:,} Samples')\n","\n","print('\\nüìÅ EXPORTIERTE DATEIEN:')\n","print(f'\\n{MODEL_READY_DIR}/')\n","print('‚îú‚îÄ‚îÄ experiment_0_1_single_city/')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ hamburg/')\n","print('‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy')\n","print('‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy')\n","print('‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl')\n","print('‚îÇ   ‚îî‚îÄ‚îÄ berlin/')\n","print('‚îÇ       ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy')\n","print('‚îÇ       ‚îú‚îÄ‚îÄ X_val.npy, y_val.npy')\n","print('‚îÇ       ‚îî‚îÄ‚îÄ scaler.pkl')\n","print('‚îú‚îÄ‚îÄ experiment_2_cross_city/')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_train_hamburg.npy, y_train_hamburg.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_train_berlin.npy, y_train_berlin.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_val_hamburg.npy, y_val_hamburg.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_val_berlin.npy, y_val_berlin.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_test_rostock_zero_shot.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ y_test_rostock_zero_shot.npy')\n","print('‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl (Hamburg+Berlin Combined)')\n","print('‚îú‚îÄ‚îÄ experiment_3_finetuning/')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ X_test_rostock_finetune_eval.npy')\n","print('‚îÇ   ‚îú‚îÄ‚îÄ y_test_rostock_finetune_eval.npy')\n","print('‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl (Copy of Exp. 2)')\n","print('‚îú‚îÄ‚îÄ feature_names.json')\n","print('‚îî‚îÄ‚îÄ label_encoder.pkl')\n","\n","print('\\nüî¨ SCALER-STRATEGIE:')\n","print('  ‚úÖ Hamburg Single-City: Scaler auf Hamburg Train gefittet')\n","print('  ‚úÖ Berlin Single-City: Scaler auf Berlin Train gefittet')\n","print('  ‚úÖ Cross-City (Exp. 2): Scaler auf Hamburg+Berlin Combined gefittet')\n","print('  ‚úÖ Fine-Tuning (Exp. 3): Nutzt Exp. 2 Scaler (kein Leakage!)')\n","\n","print('\\n‚úÖ KEIN DATA LEAKAGE - Scaler immer NUR auf Train gefittet!')\n","print('\\n‚è≠Ô∏è  N√ÑCHSTER SCHRITT: Experiment 0 - RF/CNN Baseline Training')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}